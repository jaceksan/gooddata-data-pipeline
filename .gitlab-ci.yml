stages:
  - extract_load
  - transform
  - analytics

##########################
# Global variables
variables:
  DBT_PROFILE_DIR: "profile"
  DBT_PROFILE: "default"
  GOODDATA_MODEL_ID: "github"

##########################
# Job templates
##########################
.base:
  image: python:3.10-alpine
  rules:
    - if: '$RUN_ALL_JOBS == "true"'
      when: manual

.extract_load:
  extends:
    - .base
  stage: extract_load
  before_script:
    - cd "$CI_PROJECT_DIR/data_transformation"
    # Use dbt profiles parser from dbt-gooddata to get connection properties to the current target database
    - cd dbt-gooddata && python setup.py install && cd ..
    - cd "extract_load"
    - pip install -r requirements.txt
  script:
    - ./extract.py $REPOSITORIES
    - ./load.py --profile-dir ../$DBT_PROFILE_DIR --target $DBT_TARGET $REPOSITORIES

.dbt:
  extends:
    - .base
  stage: transform
  before_script:
    - cd "$CI_PROJECT_DIR/data_transformation"
    - pip install -r requirements.txt
    # TODO - publish to pip
    - cd dbt-gooddata && python setup.py install && cd ..
    - dbt deps
  script:
    - dbt run --profiles-dir $DBT_PROFILE_DIR --profile $DBT_PROFILE --target $DBT_TARGET
    - dbt test --profiles-dir $DBT_PROFILE_DIR --profile $DBT_PROFILE --target $DBT_TARGET
    - dbt-gooddata deploy_models
    - dbt-gooddata upload_notification

.gooddata:
  extends:
    - .base
  stage: analytics
  before_script:
    - cd "$CI_PROJECT_DIR/data_transformation"
    - pip install -r requirements.txt
    # TODO - publish to pip
    - cd dbt-gooddata && python setup.py install && cd ..
    - dbt deps
  script:
    # Compile to generate manifest.json, which is parsed by dbt-gooddata module
    - dbt compile --profiles-dir $DBT_PROFILE_DIR --profile $DBT_PROFILE --target $DBT_TARGET
    - dbt-gooddata deploy_analytics
    - dbt-gooddata test_insights

#############
# Pre-merge
#############
extract_load_dev:
  extends:
    - .extract_load
  variables:
    DBT_TARGET: dev
    # Load only 1 repo to speed up testing (dev only)
    REPOSITORIES: "--repositories gooddata/gooddata-python-sdk"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - extract_load/**/*
        - .gitlab-ci.yml

dbt_dev:
  extends:
    - .dbt
  variables:
    DBT_TARGET: dev
    GOODDATA_WORKSPACE_ID: "development"
    GOODDATA_WORKSPACE_TITLE: "Development"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - extract_load/**/*
        - data_transformation/**/*
        - .gitlab-ci.yml

gooddata_dev:
  extends:
    - .gooddata
  variables:
    DBT_TARGET: dev
    GOODDATA_WORKSPACE_ID: "development"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - data_transformation/**/*
        - analytics/**/*
        - .gitlab-ci.yml

#############
# Post-merge
#############

extract_load_staging:
  extends:
    - .extract_load
  variables:
    DBT_TARGET: staging
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - .gitlab-ci.yml

dbt_staging:
  extends:
    - .dbt
  variables:
    DBT_TARGET: staging
    GOODDATA_WORKSPACE_ID: "staging"
    GOODDATA_WORKSPACE_TITLE: "Staging"
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - data_transformation/**/*
        - .gitlab-ci.yml

gooddata_staging:
  extends:
    - .gooddata
  variables:
    DBT_TARGET: staging
    GOODDATA_WORKSPACE_ID: staging
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - data_transformation/**/*
        - analytics/**/*
        - .gitlab-ci.yml

##########################
# Post-merge - PROD
##########################
extract_load_prod:
  extends:
    - .extract_load
  variables:
    DBT_TARGET: prod
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - .gitlab-ci.yml
    # The pipeline scheduler triggers only PROD jobs
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'

dbt_prod:
  extends:
    - .dbt
  variables:
    DBT_TARGET: prod
    GOODDATA_WORKSPACE_ID: "production"
    GOODDATA_WORKSPACE_TITLE: "Production"
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - data_transformation/**/*
        - .gitlab-ci.yml
    # The pipeline scheduler triggers only PROD jobs
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'

gooddata_prod:
  extends:
    - .gooddata
  variables:
    DBT_TARGET: prod
    GOODDATA_WORKSPACE_ID: production
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - analytics/**/*
        - .gitlab-ci.yml
