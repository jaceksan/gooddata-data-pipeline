stages:
  - extract_load
  - transform
  - analytics

##########################
# Job templates
##########################
.base:
  image: python:3.10-alpine
  rules:
    - if: '$RUN_ALL_JOBS == "true"'
      when: manual

.extract_load:
  extends:
    - .base
  stage: extract_load
  script:
    - cd "$CI_PROJECT_DIR/extract_load"
    - pip install -r requirements.txt
    - ./extract.py
    - ./load.py

.dbt:
  extends:
    - .base
  stage: transform
  variables:
    POSTGRES_DBNAME: cicd_dev
  script:
    - cd "$CI_PROJECT_DIR/data_transformation"
    - pip install -r requirements.txt
    - dbt deps
    - dbt run --profiles-dir profile --target dev
    - dbt test --profiles-dir profile --target dev

.gooddata:
  extends:
    - .base
  stage: analytics
  script:
    - cd "$CI_PROJECT_DIR/analytics"
    - pip install -r requirements.txt
    # Deliver into dev workspace
    # Data source properties are stored in Gitlab ENV vars
    # If admin changes them, he has to run this job manually (RUN_ALL_JOBS=true) to deliver new DS definition
    - python gooddata_register_data_source.py
    # Notify GoodData that data has been changed by ETL
    - python gooddata_upload_notification.py
    # It takes the metadata of analytics saved in folder structure and put it in the staging workspace.
    # It is good to save metadata in the folder structure because you immediately gain versioning of analytics.
    - python gooddata_load_metadata.py -w $WORKSPACE
    # Test that all insights are still executable
    - python gooddata_tests.py -w $WORKSPACE

#############
# Pre-merge
#############
extract_load_dev:
  extends:
    - .extract_load
  variables:
    POSTGRES_DBNAME: cicd_dev
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - extract_load/**/*
        - .gitlab-ci.yml

dbt_dev:
  extends:
    - .dbt
  variables:
    POSTGRES_DBNAME: cicd_dev
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - extract_load/**/*
        - data_transformation/**/*
        - .gitlab-ci.yml

gooddata_dev:
  extends:
    - .gooddata
  variables:
    POSTGRES_DBNAME: cicd_dev
    GOODDATA_DATA_SOURCE_ID: cicd_dev
    WORKSPACE: development
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - data_transformation/**/*
        - analytics/**/*
        - .gitlab-ci.yml

#############
# Post-merge
#############

extract_load_staging:
  extends:
    - .extract_load
  variables:
    POSTGRES_DBNAME: cicd_staging
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - .gitlab-ci.yml

dbt_staging:
  extends:
    - .dbt
  variables:
    POSTGRES_DBNAME: cicd_staging
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - data_transformation/**/*
        - .gitlab-ci.yml

gooddata_staging:
  extends:
    - .gooddata
  variables:
    POSTGRES_DBNAME: cicd_staging
    GOODDATA_DATA_SOURCE_ID: cicd_staging
    WORKSPACE: staging
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - data_transformation/**/*
        - analytics/**/*
        - .gitlab-ci.yml

##########################
# Post-merge - PROD
##########################
extract_load_prod:
  extends:
    - .extract_load
  variables:
    POSTGRES_DBNAME: cicd_prod
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - .gitlab-ci.yml
    # The pipeline scheduler triggers only PROD jobs
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'

dbt_prod:
  extends:
    - .dbt
  variables:
    POSTGRES_DBNAME: cicd_prod
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - extract_load/**/*
        - data_transformation/**/*
        - .gitlab-ci.yml
    # The pipeline scheduler triggers only PROD jobs
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'

gooddata_prod:
  extends:
    - .gooddata
  variables:
    POSTGRES_DBNAME: cicd_prod
    GOODDATA_DATA_SOURCE_ID: cicd_prod
    WORKSPACE: production
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - analytics/**/*
        - .gitlab-ci.yml

###############################
# Triggered only from scheduler
###############################
# We need to notify GoodData that extract/load/transform delivered new data
gooddata_prod_notify_data_changed:
  extends:
    - .base
  stage: analytics
  variables:
    POSTGRES_DBNAME: cicd_prod
    GOODDATA_DATA_SOURCE_ID: cicd_prod
  script:
    - cd "$CI_PROJECT_DIR/analytics"
    - pip install -r requirements.txt
    - python gooddata_upload_notification.py
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'
