stages:
  - build
  - extract_load
  - transform
  - analytics

##########################
# Global variables
variables:
  DBT_PROFILE_DIR: "profile"
  DBT_PROFILE: "default"
  GOODDATA_MODEL_ID: "github"
  GOODDATA_UPPER_CASE: "--gooddata-upper-case"
  # TODO - store the state in a so-called custom state backend, e.g. in AWS S3, and get rid of PostgreSQL
  # https://docs.meltano.com/concepts/state_backends#aws-s3
  POSTGRES_HOST: "db.bit.io"
  POSTGRES_PORT: 5432
  POSTGRES_USER: "cicd"
  SNOWFLAKE_ACCOUNT: "gooddata"
  SNOWFLAKE_USER: "cicd"
  SNOWFLAKE_WAREHOUSE: "DEMO_WH"
  INPUT_SCHEMA: "cicd_input_stage"
  OUTPUT_SCHEMA: "cicd_output_stage"
  MELTANO_CUSTOM_IMAGE_BASE: "gooddata-data-pipeline-meltano"
  MELTANO_VERSION: "v2.12.0-python3.10"
  MELTANO_CUSTOM_IMAGE: "$CI_REGISTRY_IMAGE/$MELTANO_CUSTOM_IMAGE_BASE:$MELTANO_VERSION"

.envs:
  # Meltano, dbt and GoodData environments have 1:1 relationship in this demo
  # But, you can design you pipeline in any alternative way, e.g. share 1 data source by multiple GoodData workspaces
  dev:
    ELT_ENVIRONMENT: "cicd_dev"
    POSTGRES_DBNAME: "jaceksan/cicd_dev"
    SNOWFLAKE_DBNAME: "CICD_DEV"
    DBT_TARGET_TITLE: "CICD demo (dev)"
    GOODDATA_WORKSPACE_ID: "cicd_demo_development"
    GOODDATA_WORKSPACE_TITLE: "$DBT_TARGET_TITLE"
  staging:
    ELT_ENVIRONMENT: "cicd_staging"
    POSTGRES_DBNAME: "jaceksan/cicd_staging"
    SNOWFLAKE_DBNAME: "CICD_STAGING"
    DBT_TARGET_TITLE: "CICD demo (staging)"
    GOODDATA_WORKSPACE_ID: "cicd_demo_staging"
    GOODDATA_WORKSPACE_TITLE: "$DBT_TARGET_TITLE"
  prod:
    ELT_ENVIRONMENT: "cicd_prod"
    POSTGRES_DBNAME: "jaceksan/cicd_prod"
    SNOWFLAKE_DBNAME: "CICD_PROD"
    DBT_TARGET_TITLE: "CICD demo (prod)"
    GOODDATA_WORKSPACE_ID: "cicd_demo_production"
    GOODDATA_WORKSPACE_TITLE: "$DBT_TARGET_TITLE"


##########################
# Job templates
##########################
.base:
  image: python:3.10-slim-bullseye

.base_rules:
  rules:
    - if: '$RUN_ALL_JOBS == "true"'
      when: manual

.docker:
  extends:
    - .base
  image: docker:latest
  services:
    - docker:18.09.7-dind # older version that does not need demand TLS (see below)
  before_script:
    - docker login -u ${CI_REGISTRY_USER} -p ${CI_REGISTRY_PASSWORD} ${CI_REGISTRY}

.extract_load:
  extends:
    - .base
  # We build a custom image on top of the official Meltano image in this pipeline
  # It contains Meltano itself, and all extractors/loaders
  image:
    name: "$MELTANO_CUSTOM_IMAGE"
    entrypoint: [""]
  stage: extract_load
  variables:
    TAP_GITHUB_AUTH_TOKEN: "$GITHUB_TOKEN"
    MELTANO_DATABASE_URI: "postgresql://$POSTGRES_USER:$POSTGRES_PASS@$POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DBNAME?options=-csearch_path%3Dmeltano&sslmode=require"
    DB_NAME: !reference[
    MELTANO_TARGET: "target-snowflake"
    # CI_DEBUG_TRACE: "true"
    GIT_STRATEGY: "none"
  artifacts:
    paths:
      - .meltano/logs/**
  script:
    - cd /project
    - meltano --environment $ELT_ENVIRONMENT run tap-github-repo $MELTANO_TARGET tap-github-org $MELTANO_TARGET

.extract_load_changes:
  changes:
    - src/meltano.yml
    - .gitlab-ci.yml

.dbt:
  extends:
    - .base
  stage: transform
  before_script:
    - cd "$CI_PROJECT_DIR/src"
    - pip install -r requirements-dbt.txt
    # TODO - publish to pip
    - cd dbt-gooddata && python setup.py install && cd ..
    - dbt deps
  script:
    - dbt run --profiles-dir $DBT_PROFILE_DIR --profile $DBT_PROFILE --target $ELT_ENVIRONMENT
    - dbt test --profiles-dir $DBT_PROFILE_DIR --profile $DBT_PROFILE --target $ELT_ENVIRONMENT
    - dbt-gooddata deploy_models $GOODDATA_UPPER_CASE
    - dbt-gooddata upload_notification

.dbt_changes:
  changes:
    - src/models/**/*
    - src/profile/**/*
    - src/dbt_project.yml
    - src/packages.yml
    - src/requirements-dbt.txt
    - src/dbt-gooddata/**/*
    - .gitlab-ci.yml

.gooddata:
  extends:
    - .base
  stage: analytics
  before_script:
    - cd "$CI_PROJECT_DIR/src"
    - pip install -r requirements-dbt.txt
    # TODO - publish to pip
    - cd dbt-gooddata && python setup.py install && cd ..
    - dbt deps
  script:
    # Compile to generate manifest.json, which is parsed by dbt-gooddata module
    - dbt compile --profiles-dir $DBT_PROFILE_DIR --profile $DBT_PROFILE --target $ELT_ENVIRONMENT
    - dbt-gooddata deploy_analytics $GOODDATA_UPPER_CASE
    - dbt-gooddata test_insights

.gooddata_changes:
  changes:
    - src/models/**/*
    - src/dbt-gooddata/**/*
    - src/gooddata_layouts/**/*
    - .gitlab-ci.yml

#############
# Pre-merge
#############
build_meltano:
  extends:
    - .docker
  stage: build
  script:
    - cd "$CI_PROJECT_DIR/src"
    - docker build 
      --build-arg MELTANO_VERSION=$MELTANO_VERSION 
      -f Dockerfile_meltano 
      -t $MELTANO_CUSTOM_IMAGE .
    - docker push $MELTANO_CUSTOM_IMAGE
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes:
        - src/Dockerfile_meltano
        - src/meltano.yml
        - .gitlab-ci.yml
    - !reference [.base_rules, rules]

extract_load_dev:
  extends:
    - .extract_load
  variables:
    ELT_ENVIRONMENT: !reference [.envs, dev, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, dev, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, dev, SNOWFLAKE_DBNAME]
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes: !reference [.extract_load_changes, changes]
    - !reference [.base_rules, rules]

dbt_dev:
  extends:
    - .dbt
  variables:
    ELT_ENVIRONMENT: !reference [.envs, dev, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, dev, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, dev, SNOWFLAKE_DBNAME]
    GOODDATA_WORKSPACE_ID: !reference [.envs, dev, GOODDATA_WORKSPACE_ID]
    DBT_TARGET_TITLE: !reference [.envs, dev, DBT_TARGET_TITLE]
    GOODDATA_WORKSPACE_TITLE: !reference [.envs, dev, GOODDATA_WORKSPACE_TITLE]
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes: !reference [.dbt_changes, changes]
    - !reference [.base_rules, rules]

gooddata_dev:
  extends:
    - .gooddata
  variables:
    ELT_ENVIRONMENT: !reference [.envs, dev, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, dev, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, dev, SNOWFLAKE_DBNAME]
    GOODDATA_WORKSPACE_ID: !reference [.envs, dev, GOODDATA_WORKSPACE_ID]
    DBT_TARGET_TITLE: !reference [.envs, dev, DBT_TARGET_TITLE]
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
      changes: !reference [.gooddata_changes, changes]
    - !reference [.base_rules, rules]

#############
# Post-merge
#############

extract_load_staging:
  extends:
    - .extract_load
  variables:
    ELT_ENVIRONMENT: !reference [.envs, staging, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, staging, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, staging, SNOWFLAKE_DBNAME]
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes: !reference [.extract_load_changes, changes]
    - !reference [.base_rules, rules]

dbt_staging:
  extends:
    - .dbt
  variables:
    ELT_ENVIRONMENT: !reference [.envs, staging, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, staging, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, staging, SNOWFLAKE_DBNAME]
    GOODDATA_WORKSPACE_ID: !reference [.envs, staging, GOODDATA_WORKSPACE_ID]
    DBT_TARGET_TITLE: !reference [.envs, staging, DBT_TARGET_TITLE]
    GOODDATA_WORKSPACE_TITLE: !reference [.envs, staging, GOODDATA_WORKSPACE_TITLE]
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes: !reference [.dbt_changes, changes]
    - !reference [.base_rules, rules]

gooddata_staging:
  extends:
    - .gooddata
  variables:
    ELT_ENVIRONMENT: !reference [.envs, staging, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, staging, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, staging, SNOWFLAKE_DBNAME]
    GOODDATA_WORKSPACE_ID: !reference [.envs, staging, GOODDATA_WORKSPACE_ID]
    DBT_TARGET_TITLE: !reference [.envs, staging, DBT_TARGET_TITLE]
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes: !reference [.gooddata_changes, changes]
    - !reference [.base_rules, rules]

##########################
# Post-merge - PROD
##########################
extract_load_prod:
  extends:
    - .extract_load
  variables:
    ELT_ENVIRONMENT: !reference [.envs, prod, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, prod, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, prod, SNOWFLAKE_DBNAME]
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes: !reference [.extract_load_changes, changes]
    # The pipeline scheduler triggers only PROD jobs
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'
    - !reference [.base_rules, rules]

dbt_prod:
  extends:
    - .dbt
  variables:
    ELT_ENVIRONMENT: !reference [.envs, prod, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, prod, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, prod, SNOWFLAKE_DBNAME]
    GOODDATA_WORKSPACE_ID: !reference [.envs, prod, GOODDATA_WORKSPACE_ID]
    DBT_TARGET_TITLE: !reference [.envs, prod, DBT_TARGET_TITLE]
    GOODDATA_WORKSPACE_TITLE: !reference [.envs, prod, GOODDATA_WORKSPACE_TITLE]
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes: !reference [.dbt_changes, changes]
    # The pipeline scheduler triggers only PROD jobs
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $RUN_ETL == "true"'
    - !reference [.base_rules, rules]

gooddata_prod:
  extends:
    - .gooddata
  variables:
    ELT_ENVIRONMENT: !reference [.envs, prod, ELT_ENVIRONMENT]
    POSTGRES_DBNAME: !reference [.envs, prod, POSTGRES_DBNAME]
    SNOWFLAKE_DBNAME: !reference [.envs, prod, SNOWFLAKE_DBNAME]
    GOODDATA_WORKSPACE_ID: !reference [.envs, prod, GOODDATA_WORKSPACE_ID]
    DBT_TARGET_TITLE: !reference [.envs, prod, DBT_TARGET_TITLE]
  rules:
    - if: '$CI_COMMIT_BRANCH == "prod" && $CI_PIPELINE_SOURCE == "push"'
      changes: !reference [.gooddata_changes, changes]
    - !reference [.base_rules, rules]
